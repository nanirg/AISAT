{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering and PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mushroom Dataset\n",
    "\n",
    "Podeis obtener el conjunto de datos en el siguiente enlace:\n",
    "\n",
    "[Mushroom Dataset](https://www.kaggle.com/uciml/mushroom-classification)\n",
    "\n",
    "Como podréis comprobar, hay muchas variables, todas ellas categóricas, por lo que exploraciones con scatterplot no nos serán útiles como en otros casos.\n",
    "\n",
    "La variable a predecir ``class`` es categórica, asi que no habrá que reescalar con funciones como el logaritmo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carga de librerías, las que hemos considerado básicas, añadid lo que queráis :)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leer conjunto de datos y primer vistazo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# leer el csv y ver un siple head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploración de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descripción del conjunto de datos, estándard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información sobre el tipo de datos de cada feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcular el número de nulos de cada feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# igual que otras veces, una linea, contar los nulos por variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Buscar valores extraños. Para ello, ver los valores distintos en cada feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtener un nuevo dataframe donde una columna sean los no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tratar aquellos valores que entendamos que sean nulos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputaciones. Podéis quitar esos puntos, imputar con la moda o dejar ese valor como una posibilidad más"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mirad cuántos valores hay en cada feature, ¿Todas las features aportan información? Si alguna no aporta información, eliminadla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dejar por el camino si procede"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separar entre variables predictoras y variables a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la variable que trata de predecir este conjunto de datos es class\n",
    "y = \n",
    "X = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Codificar correctamente las variables categóricas a numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot, es una linea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train test split, duh ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os lo dejamos a todos igual :)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un conjunto de datos del que aún no hemos visto nada (no hay dibujitos) así que vamos a hacer algunos. Tenemos el problema de que son muchas variables... Bueno, **PCA al rescate**: le pedimos que nos de dos dimensiones y las pintamos, sabemos que serán **aquellas que retengan más información**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca =       # metodo de sklearn \n",
    "pca.fit(X_train)\n",
    "\n",
    "# representar en un scatterplot y poner en color las etiquetas de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que está bastante separadito, parece que a ojo mucho se puede ver :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igualmente, y para evitar casos como el de la calidad del vino ;), vamos a entrenar un clasificador a ver qué tal lo hace antes de editar más"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Definir el clasificador y el número de estimadores\n",
    "# entrenar en train\n",
    "# calcular la precisión sobre test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh sh*t, resulta que lo clava!! Vuelve arriba, revisa que hayas partido bien la variable predictora, corre!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naaaah que es broma, está bien, es un conjunto sencillete y Random Forest es muy bueno en su trabajo xD Igualmente, vamos a ver qué tamaño tenemos de dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ufffffff ¿Muchas features no? Vamos a reducir a ver qué tal.¿Cómo? Venga, mira como se llama la sección, seguro que te da una pista ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_features = # definir un rango de valores a probar\n",
    "scores = []\n",
    "\n",
    "for n in n_features:\n",
    "    \n",
    "    # Hacer PCA sobre X_train\n",
    "    # 1- Definir PCA\n",
    "    # 2- Aprender PCA sobre X_train\n",
    "    \n",
    "    # Entrenar Random Forest\n",
    "    # 1- Definir el RF\n",
    "    # 2- Entrenar clasificador\n",
    "    \n",
    "    # Guardar el score\n",
    "    \n",
    "    \n",
    "sns.lineplot(x=n_features, y=scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vale, estamos viendo que a partir de unas 10 features ya tenemos el score que queríamos y además hemos reducido las variables a un 10% de las que teníamos, incluso menos que las variables originales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo que el conjunto de datos es sencillito, podemos intentar hacer algo de clustering a ver qué información podemos obtener.\n",
    "\n",
    "El primer paso va a ser importar la función de Kmeans de sklearn, y a partir de ahi, vamos a buscar el valor óptimo de clusters. Como hemos visto anteriormente, este valor lo obtenemos, por ejemplo, del codo de la gráfica que representa el total de las distancias de los puntos a los centros de los clusters asociados. Os dejo la página de la documentación de sklearn para que lo busquéis:\n",
    "\n",
    "[K-Means on sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n",
    "\n",
    "Con esto solo hay que ahora generar los modelos de kmeans, evaluar y pintar la gráfica para los valores de ``k`` que establezcais\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "scores = []\n",
    "k_values = # definir un rango\n",
    "for a in k_values:\n",
    "    \n",
    "    # Definir Kmeans y ajustar\n",
    "    # Guardar la predicción\n",
    "        \n",
    "sns.lineplot(x=k_values, y=scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el valor que hayáis obtenido de la gráfica, podéis obtener una buena aproximación de Kmeans y con ello podemos pasar a explorar cómo de bien han separado la información los distintos clusters. Para ello, se va a hacer un ``factorplot``, seaborn os lo hará solito. Con esto lo que se pretende ver es la distribución de la varaible a predecir en función del cluster que haya determinado Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Aprender Kmeans con el valor de K obtenido\n",
    "\n",
    "kmeans = # Definir y entrenar Kmeans\n",
    "\n",
    "# Preparar el factorplot\n",
    "\n",
    "\n",
    "# Pintar\n",
    "ax = sns.factorplot(col=, x=, data=, kind='count',col_wrap=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver qué tal queda esto pintado. Para ello, repetimos el scatterplot de antes pero usando como color el cluster asignado por kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Entrenar PCA para representar\n",
    "\n",
    "# Representar cin los clusters como color \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Es bastante parecido no? Tan bueno como el maravilloso Random Forest no es, pero ha conseguido identificar bastante bien los distintos puntos del dataset. De hecho, el diagrama de factor que hemos visto antes muestra que solo un par de clusters son imprecisos, el resto de por si nos saca la variable a predecir ya limpia."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
