{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "\n",
    "Os dejamos aqui algunas librerías para que esta parte la tengais ya orientada. Va a ser una GAN pequeñita, asi que solo os proponemos las capas sencillas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from IPython.core.debugger import Tracer\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga del conjunto de datos\n",
    "\n",
    "Como el conjunto de datos de MNISt ya es más que conocido y está más que trabajado, vamos a intentar un conjunto de datos de un tamaño similar pero que suba un poco la complejidad. En este caso, vamos a utilizar el conjunto de datos de Fashion MNIST de Zalando, que podéis descargar de aquí:\n",
    "\n",
    "[Fashion MNIST](https://www.kaggle.com/zalando-research/fashionmnist)\n",
    "\n",
    "La carga de datos es trivial, solo completad el método para que os devuelva ``X_train, y_train``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fashion_mnist(input_rows=28, input_cols=28, path='fashion-mnist_train.csv'):\n",
    "    # read, drop labels, transform into matrix\n",
    "    \n",
    "    df = \n",
    "    X_train = \n",
    "    \n",
    "    #extract the labels and transform into matrix\n",
    "    y_train = \n",
    "    return X_train, y_train\n",
    "X_train, y_train = load_fashion_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definición de parámetros para el modelo\n",
    "\n",
    "En esta sección debéis definir/parametrizar algunas de las variables que vais a utilizar en el modelo constantemente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir parámetros característicos de la imágen (ancho, alto, número de canales). \n",
    "# Estos parámetros definen la entrada del discriminador y la salida del generador\n",
    "\n",
    "WIDTH = \n",
    "HEIGHT = \n",
    "CHANNELS = \n",
    "SHAPE = (WIDTH, HEIGHT, CHANNELS)\n",
    "\n",
    "# Definir parámetros de entrenamiento\n",
    "\n",
    "OPTIMIZER = \n",
    "NOISE_SIZE = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN\n",
    "\n",
    "### Generador\n",
    "\n",
    "Construir el generador. Sabéis que es un modelo de Keras que tiene de tamaño de entrada el tamaño de ruido que hayáis definido y como tamaño de salida la forma de la imágen con la que estáis trabajando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnrtr = Sequential()\n",
    "\n",
    "\n",
    "# Fill here: (keras tiene una capa reshape, a lo mejor os es util)\n",
    "\n",
    "# Cuatro capas deberían dar más que de sobra\n",
    "\n",
    "gnrtr.compile(loss='binary_crossentropy', optimizer=OPTIMIZER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminador\n",
    "\n",
    "Construir el modelo discriminador. En este caso solo vamos a entrenarlo con imágenes correctas vs incorrectas, así que la salida será una única neurona. Obviamente como entrada tendrá la forma de la imágen. Esta no deja de ser una red de clasificación normal y corriente (un canal e imágenes sencillas, no debería ni hacer falta convolucionales). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dscrmntr = Sequential()\n",
    "\n",
    "# Fill here, unas 3 capas\n",
    "\n",
    "dscrmntr.compile(loss='binary_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN!!\n",
    "\n",
    "Sorpresa sorpresa, solo hay que juntar los dos modelos en uno nuevo, primero el generador y luego el discriminador\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir modelo combinado (GAN)\n",
    "\n",
    "dscrmntr.trainable = False # importante de cara a que se quede quieto al entrenar el modelo conjunto, entrenando el generador\n",
    "model = Sequential()\n",
    "model.add(gnrtr)\n",
    "model.add(dscrmntr)\n",
    "model.compile(loss='binary_crossentropy', optimizer=OPTIMIZER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proceso de entrenamiento\n",
    "\n",
    "¿Ya creiais que iba a haber un par de ``fits`` por aqui y listo no? Ha! In your face! Hay que entrenar primero el discriminador con imágenes correctas e incorrectas y luego el generador para que intente engañarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch =  # tamaño del batch\n",
    "epochs =  # número de iteraciones, probad con decenas de miles, tampoco muchas ;)\n",
    "interval =  # cada cuanto se comprueba, uno o dos ordenes inferiores que epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dejamos esta función aquí para pintar las imágenes que salen de vez en cuando para que veáis el progreso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(gnrtr, save2file=False,  samples=16, step=0):\n",
    "    noise = np.random.normal(0, 1, (samples,NOISE_SIZE))\n",
    "    images = gnrtr.predict(noise)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(images.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        image = images[i, :, :, :]\n",
    "        image = np.reshape(image, [ HEIGHT, WIDTH ])\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bucle de entrenamiento, si si, a pedal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    ## Entrenar Discriminador\n",
    "    \n",
    "    # seleccionar aleatoriamente un índice VIABLE\n",
    "    # seleccionar batchmedios de imágenes reales\n",
    "    # generar ruido\n",
    "    # aplicar el generador al ruido\n",
    "    # crear conjunto de entrenamiento para el discriminador\n",
    "    # crear etiquetas para el discriminador, 1 a las imagenes reales, 0 a las falsas\n",
    "    # entrenar discriminador solo para ese batch, buscad en Keras\n",
    "\n",
    "\n",
    "    ## Entrenar Generador\n",
    "\n",
    "    # generar ruido\n",
    "    # generar etiquetas objetivo, todas a 1\n",
    "    gnrtr_loss =  # entrenar generador para ese batch\n",
    "    \n",
    "    print ('epoch: %d, [Discriminator :: d_loss: %f], [ Generator :: loss: %f]' % (cnt, dscrmntr_loss[0], gnrtr_loss))\n",
    "    if epoch % interval == 0 : \n",
    "        plot_images(gnrtr=gnrtr, step=cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What a load of crap, ain't it?\n",
    "\n",
    "Como habréis podido ver, las imágenes generadas no han salido mal, han salido peor. ¿Sabemos decir por qué?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
