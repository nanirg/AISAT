{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HeadPoseAI6.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"DaHdThFcsWNY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":83},"outputId":"5d5454f2-044c-49f6-8f53-57db4c2d1ca4","executionInfo":{"status":"ok","timestamp":1576436066270,"user_tz":-60,"elapsed":5611,"user":{"displayName":"David Griñán","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDI6DlGgI_9LtxTATZ_j4K_YefyrzzQkvtP4HwYeA=s64","userId":"04434285738646101374"}}},"source":["import cv2  # OpenCV 2 for capturing frames from the video\n","import os  # For managing paths and directories in the project\n","import shutil  # High level file operations\n","import numpy as np  # Arrays\n","import keras  # High level NN API\n","from PIL import Image, ImageOps # For image processing\n","from pathlib import Path  # For easily managing paths\n","from IPython import display  # For displaying images inline with the notebook\n","from sklearn.model_selection import train_test_split  # For train-test splitting\n","from tqdm import tqdm\n","import re\n","import requests\n","import pandas as pd\n","import glob"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"fVIivPo6shdi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"d2f3c486-100e-4b38-c8ae-d8651aa55ffb","executionInfo":{"status":"ok","timestamp":1576436071183,"user_tz":-60,"elapsed":10507,"user":{"displayName":"David Griñán","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDI6DlGgI_9LtxTATZ_j4K_YefyrzzQkvtP4HwYeA=s64","userId":"04434285738646101374"}}},"source":["# Download image dataset\n","import requests\n","url = 'http://www-prima.inrialpes.fr/perso/Gourier/Faces/HeadPoseImageDatabase.tar.gz'\n","file = 'HeadPoseImageDatabase.tar.gz'\n","r = requests.get(url, allow_redirects=True)\n","open(file, 'wb').write(r.content)\n"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["28512828"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"hEQMelVasyiX","colab_type":"code","colab":{}},"source":["# Uncompress the dataset, several folders created, one per person\n","!tar xfz HeadPoseImageDatabase.tar.gz"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hey0GD5ctEQO","colab_type":"code","colab":{}},"source":["df = pd.DataFrame()\n","# two character groups,  composed of a non-word and a number of at least one digit\n","regex = r'(\\W\\d+)(\\W\\d+)'\n","jpg_list = []\n","# loop for every Person folder and every txt file in it and obtain jpg list in order\n","for txt_path in glob.glob(\"Person*/*txt\"):\n","    jpg_path = txt_path[:-3] + \"jpg\"\n","    jpg_list.append(jpg_path)\n","    df = df.append(pd.read_csv(txt_path, header=None).T)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r8sjW6Btv2mE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"9d39afb5-beaa-40ea-b608-f019560b3244","executionInfo":{"status":"ok","timestamp":1576436080310,"user_tz":-60,"elapsed":19607,"user":{"displayName":"David Griñán","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDI6DlGgI_9LtxTATZ_j4K_YefyrzzQkvtP4HwYeA=s64","userId":"04434285738646101374"}}},"source":["# In the dataframe we now have the contents of the txt file: name, content, Xcoord, Ycoord, Width, Height\n","df.head()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>person05242+0-60.jpg</td>\n","      <td>Face</td>\n","      <td>204</td>\n","      <td>130</td>\n","      <td>92</td>\n","      <td>100</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>person05225-30+75.jpg</td>\n","      <td>Face</td>\n","      <td>44</td>\n","      <td>172</td>\n","      <td>70</td>\n","      <td>97</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>person05166+30-90.jpg</td>\n","      <td>Face</td>\n","      <td>186</td>\n","      <td>88</td>\n","      <td>85</td>\n","      <td>102</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>person05160+15+15.jpg</td>\n","      <td>Face</td>\n","      <td>120</td>\n","      <td>108</td>\n","      <td>101</td>\n","      <td>101</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>person05117-30-45.jpg</td>\n","      <td>Face</td>\n","      <td>223</td>\n","      <td>130</td>\n","      <td>96</td>\n","      <td>101</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       0     1    2    3    4    5\n","0   person05242+0-60.jpg  Face  204  130   92  100\n","0  person05225-30+75.jpg  Face   44  172   70   97\n","0  person05166+30-90.jpg  Face  186   88   85  102\n","0  person05160+15+15.jpg  Face  120  108  101  101\n","0  person05117-30-45.jpg  Face  223  130   96  101"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"cYOKloDcwReq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":237},"outputId":"67b18c22-7723-42bb-c809-97c9e2c2c97f","executionInfo":{"status":"ok","timestamp":1576436080312,"user_tz":-60,"elapsed":19600,"user":{"displayName":"David Griñán","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDI6DlGgI_9LtxTATZ_j4K_YefyrzzQkvtP4HwYeA=s64","userId":"04434285738646101374"}}},"source":["df = df.drop(1, axis=1)\n","# Show example of file names to extract pattern\n","df[0]"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0     person05242+0-60.jpg\n","0    person05225-30+75.jpg\n","0    person05166+30-90.jpg\n","0    person05160+15+15.jpg\n","0    person05117-30-45.jpg\n","             ...          \n","0    person13153+15-90.jpg\n","0    person13132-15-15.jpg\n","0    person13213-60+90.jpg\n","0    person13290+60+75.jpg\n","0    person13283+60-30.jpg\n","Name: 0, Length: 2790, dtype: object"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"784key2VzMs3","colab_type":"code","colab":{}},"source":["#Extract tilt value, first number in the file name, and Pan value, second number in the file name\n","df[\"T\"] = df[0].apply(lambda name: int(re.findall(regex, name)[0][0]))\n","df[\"P\"] = df[0].apply(lambda name: int(re.findall(regex, name)[0][1]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wzfpYbUazdVx","colab_type":"code","colab":{}},"source":["def img2array(image_path, shape):\n","    image = Image.open(image_path)\n","    image_resized = image.resize(shape, Image.ANTIALIAS)\n","    img_array = np.asarray(image_resized)\n","    return img_array\n","\n","\n","df[\"imgpath\"] = jpg_list\n","df[\"Image\"] = df['imgpath'].apply(lambda img: img2array(img, (224, 224)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kDP6h_gP074S","colab_type":"code","colab":{}},"source":["df = df.drop([0, \"imgpath\"], axis=1)\n","df.columns = [\"X\", \"Y\", \"H\", \"W\", \"T\", \"P\", \"Image\"]\n","df.X = df.X.astype(int)\n","df.Y = df.Y.astype(int)\n","df.H = df.H.astype(int)\n","df.W = df.W.astype(int)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EU8Jr48P1A43","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"d0f5b3ea-5946-430d-c6fb-9e6dc9d6178b","executionInfo":{"status":"ok","timestamp":1576436100429,"user_tz":-60,"elapsed":39687,"user":{"displayName":"David Griñán","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDI6DlGgI_9LtxTATZ_j4K_YefyrzzQkvtP4HwYeA=s64","userId":"04434285738646101374"}}},"source":["df.head()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>X</th>\n","      <th>Y</th>\n","      <th>H</th>\n","      <th>W</th>\n","      <th>T</th>\n","      <th>P</th>\n","      <th>Image</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>204</td>\n","      <td>130</td>\n","      <td>92</td>\n","      <td>100</td>\n","      <td>0</td>\n","      <td>-60</td>\n","      <td>[[[22, 22, 24], [16, 16, 18], [53, 53, 55], [1...</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>44</td>\n","      <td>172</td>\n","      <td>70</td>\n","      <td>97</td>\n","      <td>-30</td>\n","      <td>75</td>\n","      <td>[[[21, 21, 21], [14, 14, 14], [57, 57, 57], [1...</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>186</td>\n","      <td>88</td>\n","      <td>85</td>\n","      <td>102</td>\n","      <td>30</td>\n","      <td>-90</td>\n","      <td>[[[21, 21, 21], [15, 15, 15], [55, 55, 55], [1...</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>120</td>\n","      <td>108</td>\n","      <td>101</td>\n","      <td>101</td>\n","      <td>15</td>\n","      <td>15</td>\n","      <td>[[[21, 21, 21], [16, 16, 16], [54, 54, 54], [1...</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>223</td>\n","      <td>130</td>\n","      <td>96</td>\n","      <td>101</td>\n","      <td>-30</td>\n","      <td>-45</td>\n","      <td>[[[22, 22, 22], [16, 16, 16], [55, 55, 55], [1...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     X    Y    H  ...   T   P                                              Image\n","0  204  130   92  ...   0 -60  [[[22, 22, 24], [16, 16, 18], [53, 53, 55], [1...\n","0   44  172   70  ... -30  75  [[[21, 21, 21], [14, 14, 14], [57, 57, 57], [1...\n","0  186   88   85  ...  30 -90  [[[21, 21, 21], [15, 15, 15], [55, 55, 55], [1...\n","0  120  108  101  ...  15  15  [[[21, 21, 21], [16, 16, 16], [54, 54, 54], [1...\n","0  223  130   96  ... -30 -45  [[[22, 22, 22], [16, 16, 16], [55, 55, 55], [1...\n","\n","[5 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"a3ZBopdj1JC7","colab_type":"code","colab":{}},"source":["# Order the dataframe with an index\n","df = df.reset_index().drop(\"index\", axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JtFC3zLN1Ws3","colab_type":"code","colab":{}},"source":["# Get X and y, which will be multidimensional, and normalize in y, deminish scale in X\n","X = np.asarray(list(df[\"Image\"]/255.))\n","y = np.array(df[[\"X\", \"Y\", \"H\", \"W\", \"T\", \"P\"]])/100."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t1pOtUCV3Inh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"0eb269f6-d315-4173-c5f7-8e0adbe745ee","executionInfo":{"status":"ok","timestamp":1576436114529,"user_tz":-60,"elapsed":53769,"user":{"displayName":"David Griñán","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDI6DlGgI_9LtxTATZ_j4K_YefyrzzQkvtP4HwYeA=s64","userId":"04434285738646101374"}}},"source":["# Explore X to address the input on the CNN\n","X.shape"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2790, 224, 224, 3)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"FQzaYv5A16My","colab_type":"code","colab":{}},"source":["# Split train/test dataset\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CXTY8Sdy20HR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":164},"outputId":"6b1937d1-b18d-431b-d8ca-471707423920","executionInfo":{"status":"ok","timestamp":1576436189184,"user_tz":-60,"elapsed":7464,"user":{"displayName":"David Griñán","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDI6DlGgI_9LtxTATZ_j4K_YefyrzzQkvtP4HwYeA=s64","userId":"04434285738646101374"}}},"source":["from keras.layers import Dense,GlobalAveragePooling2D\n","from keras.applications import MobileNet\n","from keras.preprocessing import image\n","from keras.models import Model\n","\n","\n","n_classes = 6\n","base_model = MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last layer\n","\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(1024,activation='relu')(x) \n","x = Dense(1024,activation='relu')(x) \n","x = Dense(512,activation='relu')(x) \n","\n","preds = Dense(n_classes,activation='linear')(x)\n","\n","model=Model(inputs=base_model.input,outputs=preds)\n","\n","model.compile(optimizer = 'Adam',\n","              loss ='mean_squared_error',\n","              metrics = ['cosine_proximity'])"],"execution_count":17,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","  warnings.warn('`input_shape` is undefined or non-square, '\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_224_tf_no_top.h5\n","17227776/17225924 [==============================] - 2s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"shTiqEVh4-UB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":605},"outputId":"44335e1b-0711-4871-c8f6-75586d416152","executionInfo":{"status":"ok","timestamp":1576436389158,"user_tz":-60,"elapsed":173828,"user":{"displayName":"David Griñán","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDI6DlGgI_9LtxTATZ_j4K_YefyrzzQkvtP4HwYeA=s64","userId":"04434285738646101374"}}},"source":["model.fit(X_train, y_train, validation_data=[X_test, y_test], epochs=12, verbose=1, batch_size= 100)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Train on 1869 samples, validate on 921 samples\n","Epoch 1/15\n","1869/1869 [==============================] - 20s 11ms/step - loss: 0.7813 - cosine_proximity: -0.8806 - val_loss: 3.9595 - val_cosine_proximity: -0.9622\n","Epoch 2/15\n","1869/1869 [==============================] - 11s 6ms/step - loss: 0.0288 - cosine_proximity: -0.9922 - val_loss: 1.2426 - val_cosine_proximity: -0.9865\n","Epoch 3/15\n","1869/1869 [==============================] - 11s 6ms/step - loss: 0.0119 - cosine_proximity: -0.9962 - val_loss: 0.5400 - val_cosine_proximity: -0.9920\n","Epoch 4/15\n","1869/1869 [==============================] - 11s 6ms/step - loss: 0.0090 - cosine_proximity: -0.9973 - val_loss: 0.1891 - val_cosine_proximity: -0.9954\n","Epoch 5/15\n","1869/1869 [==============================] - 11s 6ms/step - loss: 0.0074 - cosine_proximity: -0.9977 - val_loss: 0.1065 - val_cosine_proximity: -0.9966\n","Epoch 6/15\n","1869/1869 [==============================] - 11s 6ms/step - loss: 0.0063 - cosine_proximity: -0.9981 - val_loss: 0.0520 - val_cosine_proximity: -0.9971\n","Epoch 7/15\n","1869/1869 [==============================] - 11s 6ms/step - loss: 0.0064 - cosine_proximity: -0.9980 - val_loss: 0.0398 - val_cosine_proximity: -0.9977\n","Epoch 8/15\n","1869/1869 [==============================] - 11s 6ms/step - loss: 0.0077 - cosine_proximity: -0.9976 - val_loss: 0.0448 - val_cosine_proximity: -0.9956\n","Epoch 9/15\n","1869/1869 [==============================] - 11s 6ms/step - loss: 0.0078 - cosine_proximity: -0.9974 - val_loss: 0.0243 - val_cosine_proximity: -0.9974\n","Epoch 10/15\n","1869/1869 [==============================] - 11s 6ms/step - loss: 0.0066 - cosine_proximity: -0.9982 - val_loss: 0.0162 - val_cosine_proximity: -0.9978\n","Epoch 11/15\n","1869/1869 [==============================] - 11s 6ms/step - loss: 0.0054 - cosine_proximity: -0.9984 - val_loss: 0.0100 - val_cosine_proximity: -0.9975\n","Epoch 12/15\n","1869/1869 [==============================] - 11s 6ms/step - loss: 0.0040 - cosine_proximity: -0.9989 - val_loss: 0.0072 - val_cosine_proximity: -0.9983\n","Epoch 13/15\n","1869/1869 [==============================] - 11s 6ms/step - loss: 0.0048 - cosine_proximity: -0.9987 - val_loss: 0.0065 - val_cosine_proximity: -0.9983\n","Epoch 14/15\n","1869/1869 [==============================] - 11s 6ms/step - loss: 0.0034 - cosine_proximity: -0.9991 - val_loss: 0.0051 - val_cosine_proximity: -0.9985\n","Epoch 15/15\n","1869/1869 [==============================] - 11s 6ms/step - loss: 0.0026 - cosine_proximity: -0.9992 - val_loss: 0.0040 - val_cosine_proximity: -0.9987\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f29d36c2fd0>"]},"metadata":{"tags":[]},"execution_count":19}]}]}